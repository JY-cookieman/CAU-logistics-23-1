{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 8-1. Natural Language Processing (NLP)\n",
    "\n",
    "**GOAL**: Let's taste how to process natural language text using Python!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Installation\n",
    "\n",
    "Before starting this tutorial, please be prepared by installing the two packages.\n",
    "- English: `nltk` package\n",
    "- Korean: `konlpy` package (+Java Development Kit)\n",
    "\n",
    "You can install them by running the following lines:\n",
    "```\n",
    ">> pip install nltk\n",
    ">> pip install jpype1\n",
    ">> pip install konlpy\n",
    "```\n",
    "\n",
    "For details, see slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.4.4)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jpype1 in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.1)\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in c:\\programdata\\anaconda3\\lib\\site-packages (from jpype1) (4.6.2)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from jpype1) (19.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->jpype1) (2.4.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->jpype1) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jpype1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in c:\\programdata\\anaconda3\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from konlpy) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from konlpy) (1.16.4)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from konlpy) (4.3.4)\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in c:\\programdata\\anaconda3\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (4.6.2)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (19.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->JPype1>=0.7.0->konlpy) (2.4.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->JPype1>=0.7.0->konlpy) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install konlpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. English NLP using NLTK package\n",
    "\n",
    "[NLTK](https://www.nltk.org/) is a pioneering NLP package built in Python.\n",
    "\n",
    "First, import the `nltk` package and download a tokenizer and a pos tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\CAU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\CAU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt') # tokenizer\n",
    "nltk.download('averaged_perceptron_tagger') # pos tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try your own sentences. You can tokenize, \n",
    "POS tag, or extract nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['by', 'the', 'end', 'of', 'this', 'course', 'i', 'will', 'be', 'a', 'great', 'data', 'scientist', '!', '100', '%', 'sure', '!']\n",
      "[('by', 'IN'), ('the', 'DT'), ('end', 'NN'), ('of', 'IN'), ('this', 'DT'), ('course', 'NN'), ('i', 'NN'), ('will', 'MD'), ('be', 'VB'), ('a', 'DT'), ('great', 'JJ'), ('data', 'NNS'), ('scientist', 'NN'), ('!', '.'), ('100', 'CD'), ('%', 'NN'), ('sure', 'JJ'), ('!', '.')]\n",
      "['end', 'course', 'i', 'data', 'scientist', '%']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"By the end of this course I will be a great data scientist! 100% sure!\"\n",
    "\n",
    "tokens = nltk.word_tokenize(sentence.lower()) # lowercase\n",
    "print(tokens)\n",
    "\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "print(tagged)\n",
    "\n",
    "nouns = [word for word, tag in tagged if tag[:2] == 'NN']\n",
    "print(nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Korean NLP using KoNLPy pacakge\n",
    "\n",
    "[KoNLPy](https://konlpy.org/) is a Python package for NLP of Korean language.\n",
    "\n",
    "It contains famous Korean POS taggers such as Hannanum (`Hannanum`), Kkma(`Kkma`), and Open Korean Text (`Okt`, aka Twitter).\n",
    "\n",
    "Here, we will use Twitter tagger. Let's load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try your own sentence. You can tokenize, POS tag, or extract nouns and phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['데이터', '분석', '수업', '이', '넘나', '재밌어서', '현기증', '이', '나요', '...', 'ㅋ', '_', 'ㅠ']\n",
      "[('데이터', 'Noun'), ('분석', 'Noun'), ('수업', 'Noun'), ('이', 'Josa'), ('넘나', 'Verb'), ('재밌어서', 'Adjective'), ('현기증', 'Noun'), ('이', 'Josa'), ('나요', 'Eomi'), ('...', 'Punctuation'), ('ㅋ', 'KoreanParticle'), ('_', 'Punctuation'), ('ㅠ', 'KoreanParticle')]\n",
      "['데이터', '분석', '수업', '현기증']\n",
      "['데이터', '데이터 분석', '데이터 분석 수업', '현기증', '분석', '수업']\n"
     ]
    }
   ],
   "source": [
    "sentence = '데이터 분석 수업이 넘나 재밌어서 현기증이 나요...ㅋ_ㅠ'\n",
    "# sentence = '공부를 하면할수록 모르는게 많다는 것을 알게 됩니다. 배운건 많았는데... 다 까먹어버렸네요? ㅋㅋ 그래도 계속 공부합니다. 재밌으니까!'\n",
    "\n",
    "tokens = okt.morphs(sentence)\n",
    "print(tokens)\n",
    "\n",
    "tagged = okt.pos(sentence)\n",
    "print(tagged)\n",
    "\n",
    "nouns = okt.nouns(sentence)\n",
    "print(nouns)\n",
    "\n",
    "phrases = okt.phrases(sentence)\n",
    "print(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
